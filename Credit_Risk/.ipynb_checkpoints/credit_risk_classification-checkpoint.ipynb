{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read the `lending_data.csv` data from the `Resources` folder into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       loan_size  interest_rate  borrower_income  debt_to_income  \\\n",
      "64435     7900.0          6.463            41400        0.275362   \n",
      "32468     7500.0          6.319            40100        0.251870   \n",
      "12526    10100.0          7.430            50500        0.405941   \n",
      "55564     9600.0          7.215            48500        0.381443   \n",
      "7981      9200.0          7.017            46600        0.356223   \n",
      "11796     7900.0          6.501            41800        0.282297   \n",
      "45815     9800.0          7.286            49200        0.390244   \n",
      "41704     8300.0          6.642            43100        0.303944   \n",
      "3059      8600.0          6.778            44400        0.324324   \n",
      "1694      9000.0          6.955            46000        0.347826   \n",
      "70700     9300.0          7.094            47400        0.367089   \n",
      "71379     9800.0          7.304            49300        0.391481   \n",
      "27086     9300.0          7.066            47100        0.363057   \n",
      "2849      9500.0          7.165            48000        0.375000   \n",
      "24061    10100.0          7.414            50400        0.404762   \n",
      "\n",
      "       num_of_accounts  derogatory_marks  total_debt  loan_status  \n",
      "64435                2                 0       11400            0  \n",
      "32468                2                 0       10100            0  \n",
      "12526                4                 1       20500            0  \n",
      "55564                4                 0       18500            0  \n",
      "7981                 3                 0       16600            0  \n",
      "11796                2                 0       11800            0  \n",
      "45815                4                 0       19200            0  \n",
      "41704                2                 0       13100            0  \n",
      "3059                 3                 0       14400            0  \n",
      "1694                 3                 0       16000            0  \n",
      "70700                3                 0       17400            0  \n",
      "71379                4                 0       19300            0  \n",
      "27086                3                 0       17100            0  \n",
      "2849                 4                 0       18000            0  \n",
      "24061                4                 1       20400            0  \n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file from the Resources folder into a Pandas DataFrame\n",
    "lending_df = pd.read_csv(\"lending_data.csv\")\n",
    "\n",
    "# Review the DataFrame\n",
    "print(lending_df.sample(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create the labels set (`y`)  from the “loan_status” column, and then create the features (`X`) DataFrame from the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data into labels and features\n",
    "# Separate the y variable, the labels\n",
    "y = lending_df['loan_status']\n",
    "\n",
    "# Separate the X variable, the features\n",
    "X = lending_df.drop('loan_status', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74544    0\n",
      "33156    0\n",
      "48022    0\n",
      "59003    0\n",
      "60396    0\n",
      "38169    0\n",
      "2390     0\n",
      "2939     0\n",
      "37477    0\n",
      "23735    0\n",
      "Name: loan_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Review the y variable Series\n",
    "print(y.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
      "0    10700.0          7.672            52800        0.431818                5   \n",
      "1     8400.0          6.692            43600        0.311927                3   \n",
      "2     9000.0          6.963            46100        0.349241                3   \n",
      "3    10700.0          7.664            52700        0.430740                5   \n",
      "4    10800.0          7.698            53000        0.433962                5   \n",
      "\n",
      "   derogatory_marks  total_debt  \n",
      "0                 1       22800  \n",
      "1                 0       13600  \n",
      "2                 0       16100  \n",
      "3                 1       22700  \n",
      "4                 1       23000  \n"
     ]
    }
   ],
   "source": [
    "# Review the X variable DataFrame\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Check the balance of the labels variable (`y`) by using the `value_counts` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    75036\n",
      "1     2500\n",
      "Name: loan_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the balance of our target values\n",
    "print(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Split the data into training and testing datasets by using `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train_test_learn module\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data using train_test_split\n",
    "# Assign a random_state of 1 to the function\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Logistic Regression Model with the Original Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 1: Fit a logistic regression model by using the training data (`X_train` and `y_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the LogisticRegression module from SKLearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the Logistic Regression model\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "reg_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit the model using training data\n",
    "reg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Save the predictions on the testing data labels by using the testing feature data (`X_test`) and the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction using the testing data\n",
    "y_pred = reg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the model’s performance by doing the following:\n",
    "\n",
    "* Calculate the accuracy score of the model.\n",
    "\n",
    "* Generate a confusion matrix.\n",
    "\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy Score: 0.9521352751368186\n"
     ]
    }
   ],
   "source": [
    "# Print the balanced_accuracy score of the model\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Balanced Accuracy Score:\", balanced_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14926    75]\n",
      " [   46   461]]\n"
     ]
    }
   ],
   "source": [
    "# Generate a confusion matrix for the model\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     15001\n",
      "           1       0.86      0.91      0.88       507\n",
      "\n",
      "    accuracy                           0.99     15508\n",
      "   macro avg       0.93      0.95      0.94     15508\n",
      "weighted avg       0.99      0.99      0.99     15508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report for the model\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Answer the following question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How well does the logistic regression model predict both the `0` (healthy loan) and `1` (high-risk loan) labels?\n",
    "\n",
    "**Answer:** WRITE YOUR ANSWER HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict a Logistic Regression Model with Resampled Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Use the `RandomOverSampler` module from the imbalanced-learn library to resample the data. Be sure to confirm that the labels have an equal number of data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)\n",
      "     -------------------------------------- 235.6/235.6 kB 4.8 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
      "     -------------------------------------- 302.0/302.0 kB 4.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\pradivan\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\pradivan\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\pradivan\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\pradivan\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.0.2)\n",
      "Installing collected packages: joblib, imbalanced-learn\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "      Successfully uninstalled joblib-1.1.0\n",
      "Successfully installed imbalanced-learn-0.11.0 joblib-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomOverSampler module form imbalanced-learn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Instantiate the random oversampler model\n",
    "# # Assign a random_state parameter of 1 to the model\n",
    "oversample = RandomOverSampler(random_state=1)\n",
    "\n",
    "# Fit the original training data to the random_oversampler model\n",
    "X_train_resampled, y_train_resampled = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    60035\n",
       "1    60035\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the distinct values of the resampled labels data\n",
    "label_counts = y_train_resampled.value_counts()\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Use the `LogisticRegression` classifier and the resampled data to fit the model and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "# Assign a random_state parameter of 1 to the model\n",
    "resampled_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit the model using the resampled training data\n",
    "resampled_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make a prediction using the testing data\n",
    "y_pred_resampled = resampled_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Evaluate the model’s performance by doing the following:\n",
    "\n",
    "* Calculate the accuracy score of the model.\n",
    "\n",
    "* Generate a confusion matrix.\n",
    "\n",
    "* Print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROS Balanced Accuracy Score: 0.9521352751368186\n"
     ]
    }
   ],
   "source": [
    "# Print the balanced_accuracy score of the model \n",
    "accuracy = balanced_accuracy_score(y_test, y_pred_resampled)\n",
    "print(\"ROS Balanced Accuracy Score:\", balanced_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14915,    86],\n",
       "       [    3,   504]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a confusion matrix for the model\n",
    "confusion_mat_resampled = confusion_matrix(y_test, y_pred_resampled)\n",
    "confusion_mat_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     15001\n",
      "           1       0.85      0.99      0.92       507\n",
      "\n",
      "    accuracy                           0.99     15508\n",
      "   macro avg       0.93      0.99      0.96     15508\n",
      "weighted avg       1.00      0.99      0.99     15508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report for the model\n",
    "classification_rep_resampled = classification_report(y_test, y_pred_resampled)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Answer the following question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How well does the logistic regression model, fit with oversampled data, predict both the `0` (healthy loan) and `1` (high-risk loan) labels?\n",
    "\n",
    "**Answer:** YOUR ANSWER HERE!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
